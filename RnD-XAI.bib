%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Arunima at 2025-01-17 21:05:20 +0100 


%% Saved with string encoding Unicode (UTF-8) 



@article{9983502,
	annote = {``heatmap-based XAI methods are not necessarily producing heatmaps that correspond to human intuition of ``explanation''.''
},
	author = {Tjoa, Erico and Guan, Cuntai},
	date-added = {2024-07-22 14:45:13 +0200},
	date-modified = {2024-07-22 14:45:30 +0200},
	doi = {10.1109/TAI.2022.3228834},
	journal = {IEEE Transactions on Artificial Intelligence},
	keywords = {Heating systems;Measurement;Artificial intelligence;Location awareness;Synthetic data;Shape;Prediction algorithms;Blackbox;computer vision;deep neural network (DNN);explainable artificial intelligence (XAI)},
	number = {4},
	pages = {858-870},
	title = {Quantifying Explainability of Saliency Methods in Deep Neural Networks With a Synthetic Dataset},
	volume = {4},
	year = {2023},
	bdsk-url-1 = {https://doi.org/10.1109/TAI.2022.3228834}}

@article{10230868,
	author = {Aysel, Halil Ibrahim and Cai, Xiaohao and Prugel-Bennett, Adam},
	date-added = {2024-07-19 15:37:52 +0200},
	date-modified = {2024-07-19 15:37:52 +0200},
	doi = {10.1109/TAI.2023.3308555},
	journal = {IEEE Transactions on Artificial Intelligence},
	keywords = {Training;Visualization;Predictive models;Linguistics;Feature extraction;Closed box;Annotations;Black box;deep neural networks (DNNs);explainable artificial intelligence (XAI);saliency maps},
	number = {5},
	pages = {2055-2066},
	title = {Multilevel Explainable Artificial Intelligence: Visual and Linguistic Bonded Explanations},
	volume = {5},
	year = {2024},
	bdsk-url-1 = {https://doi.org/10.1109/TAI.2023.3308555}}

@article{10101766,
	author = {Bharati, Subrato and Mondal, M. Rubaiyat Hossain and Podder, Prajoy},
	date-added = {2024-07-19 14:52:34 +0200},
	date-modified = {2024-07-19 14:52:34 +0200},
	doi = {10.1109/TAI.2023.3266418},
	journal = {IEEE Transactions on Artificial Intelligence},
	keywords = {Artificial intelligence;Medical services;Medical diagnostic imaging;Systematics;Standards;Guidelines;Electronic mail;Deep learning (DL);explainable artificial intelligence (XAI);healthcare;medical care;medical imaging;medicine},
	number = {4},
	pages = {1429-1442},
	title = {A Review on Explainable Artificial Intelligence for Healthcare: Why, How, and When?},
	volume = {5},
	year = {2024},
	bdsk-url-1 = {https://doi.org/10.1109/TAI.2023.3266418}}

@article{markert2022visualizing,
	annote = {This uses LRP, saliency maps, SHAP on DeepSpeech E2E ASR model.
``Secure ASR''
``Better accuracy ASR''
``Voice controlled cars - safety is a concern''
``Adversarial attack''
},
	author = {Markert, Karla and Parracone, Romain and Kulakov, Mykhailo and Sperl, Philip and Kao, Ching-Yu and B{\"o}ttinger, Konstantin},
	date-added = {2024-07-19 14:41:24 +0200},
	date-modified = {2024-07-22 16:44:14 +0200},
	journal = {arXiv preprint arXiv:2202.00673},
	title = {Visualizing Automatic Speech Recognition--Means for a Better Understanding?},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAQMjIwMi4wMDY3M3YxLnBkZk8RAVIAAAAAAVIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAONck9NCRAAB/////xAyMjAyLjAwNjczdjEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////4sArcAAAAAAAAAAAAAEAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACACovOlVzZXJzOmFydW5pbWE6RG93bmxvYWRzOjIyMDIuMDA2NzN2MS5wZGYADgAiABAAMgAyADAAMgAuADAAMAA2ADcAMwB2ADEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAChVc2Vycy9hcnVuaW1hL0Rvd25sb2Fkcy8yMjAyLjAwNjczdjEucGRmABMAAS8AABUAAgAO//8AAAAIAA0AGgAkADcAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAABjQ==}}

@article{electronics12051092,
	abstract = {In a wide range of industries and academic fields, artificial intelligence is becoming increasingly prevalent. AI models are taking on more crucial decision-making tasks as they grow in popularity and performance. Although AI models, particularly machine learning models, are successful in research, they have numerous limitations and drawbacks in practice. Furthermore, due to the lack of transparency behind their behavior, users need more understanding of how these models make specific decisions, especially in complex state-of-the-art machine learning algorithms. Complex machine learning systems utilize less transparent algorithms, thereby exacerbating the problem. This survey analyzes the significance and evolution of explainable AI (XAI) research across various domains and applications. Throughout this study, a rich repository of explainability classifications and summaries has been developed, along with their applications and practical use cases. We believe this study will make it easier for researchers to understand all explainability methods and access their applications simultaneously.},
	article-number = {1092},
	author = {Nagahisarchoghaei, Mohammad and Nur, Nasheen and Cummins, Logan and Nur, Nashtarin and Karimi, Mirhossein Mousavi and Nandanwar, Shreya and Bhattacharyya, Siddhartha and Rahimi, Shahram},
	date-added = {2024-07-09 07:36:52 +0200},
	date-modified = {2024-07-09 07:36:52 +0200},
	doi = {10.3390/electronics12051092},
	issn = {2079-9292},
	journal = {Electronics},
	number = {5},
	title = {An Empirical Survey on Explainable AI Technologies: Recent Trends, Use-Cases, and Categories from Technical and Application Perspectives},
	url = {https://www.mdpi.com/2079-9292/12/5/1092},
	volume = {12},
	year = {2023},
	bdsk-url-1 = {https://www.mdpi.com/2079-9292/12/5/1092},
	bdsk-url-2 = {https://doi.org/10.3390/electronics12051092}}

@inproceedings{10031189,
	author = {Singla, Yaman Kumar and Shah, Jui and Chen, Changyou and Shah, Rajiv Ratn},
	booktitle = {2022 IEEE International Conference on Data Mining Workshops (ICDMW)},
	date-added = {2024-07-01 07:54:51 +0200},
	date-modified = {2024-07-01 07:55:19 +0200},
	doi = {10.1109/ICDMW58026.2022.00120},
	keywords = {Speech recognition interpretability;Bit error rate;Semantics;Syntactics;Transformers;Feature extraction;Data models;Natural language processing;Interpretability;Transformers;wav2vec2.0;Audio Transformers;Language Delivery;Language Structure},
	pages = {910-925},
	title = {What Do Audio Transformers Hear? Probing Their Representations For Language Delivery \& Structure},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBlV2hhdF9Eb19BdWRpb19UcmFuc2Zvcm1lcnNfSGVhcl9Qcm9iaW5nX1RoZWlyX1JlcHJlc2VudGF0aW9uc19Gb3JfTGFuZ3VhZ2VfRGVsaXZlcnlfYW1wX1N0cnVjdHVyZS5wZGZPEQKoAAAAAAKoAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADjXJPTQkQAAf////8fV2hhdF9Eb19BdWRpb19UcmFuI0ZGRkZGRkZGLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////+KoEX8AAAAAAAAAAAABAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgB/LzpVc2VyczphcnVuaW1hOkRvd25sb2FkczpXaGF0X0RvX0F1ZGlvX1RyYW5zZm9ybWVyc19IZWFyX1Byb2JpbmdfVGhlaXJfUmVwcmVzZW50YXRpb25zX0Zvcl9MYW5ndWFnZV9EZWxpdmVyeV9hbXBfU3RydWN0dXJlLnBkZgAADgDMAGUAVwBoAGEAdABfAEQAbwBfAEEAdQBkAGkAbwBfAFQAcgBhAG4AcwBmAG8AcgBtAGUAcgBzAF8ASABlAGEAcgBfAFAAcgBvAGIAaQBuAGcAXwBUAGgAZQBpAHIAXwBSAGUAcAByAGUAcwBlAG4AdABhAHQAaQBvAG4AcwBfAEYAbwByAF8ATABhAG4AZwB1AGEAZwBlAF8ARABlAGwAaQB2AGUAcgB5AF8AYQBtAHAAXwBTAHQAcgB1AGMAdAB1AHIAZQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAfVVzZXJzL2FydW5pbWEvRG93bmxvYWRzL1doYXRfRG9fQXVkaW9fVHJhbnNmb3JtZXJzX0hlYXJfUHJvYmluZ19UaGVpcl9SZXByZXNlbnRhdGlvbnNfRm9yX0xhbmd1YWdlX0RlbGl2ZXJ5X2FtcF9TdHJ1Y3R1cmUucGRmAAATAAEvAAAVAAIADv//AAAACAANABoAJACMAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAzg=},
	bdsk-url-1 = {https://doi.org/10.1109/ICDMW58026.2022.00120}}

@inproceedings{10.1145/3617233.3617265,
	abstract = {Deep neural networks are a promising tool for Audio Event Classification. In contrast to other data like natural images, there are many sensible and non-obvious representations for audio data, which could serve as input to these models. Due to their black-box nature, the effect of different input representations has so far mostly been investigated by measuring classification performance. In this work, we leverage eXplainable AI (XAI), to understand the underlying classification strategies of models trained on different input representations. Specifically, we compare two model architectures with regard to relevant input features used for Audio Event Detection: one directly processes the signal as the raw waveform, and the other takes its time-frequency spectrogram representation as input. We show how relevance heatmaps obtained via Layer-wise Relevance Propagation uncover representation-dependent decision strategies. With these insights, we can make a well-informed decision about the best model and input representation in terms of robustness and representativity. Further, we can test whether the model's classification strategies align with human requirements.},
	address = {New York, NY, USA},
	author = {Frommholz, Annika and Seipel, Fabian and Lapuschkin, Sebastian and Samek, Wojciech and Vielhaben, Johanna},
	booktitle = {Proceedings of the 20th International Conference on Content-Based Multimedia Indexing},
	date-added = {2024-06-24 17:25:12 +0200},
	date-modified = {2024-06-24 17:25:12 +0200},
	doi = {10.1145/3617233.3617265},
	isbn = {9798400709128},
	location = {Orleans, France},
	numpages = {7},
	pages = {126--132},
	publisher = {Association for Computing Machinery},
	series = {CBMI '23},
	title = {XAI-based Comparison of Audio Event Classifiers with different Input Representations},
	url = {https://doi.org/10.1145/3617233.3617265},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxATMzYxNzIzMy4zNjE3MjY1LnBkZk8RAWAAAAAAAWAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAONck9NCRAAB/////xMzNjE3MjMzLjM2MTcyNjUucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////4p9cqAAAAAAAAAAAAAEAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACAC0vOlVzZXJzOmFydW5pbWE6RG93bmxvYWRzOjM2MTcyMzMuMzYxNzI2NS5wZGYAAA4AKAATADMANgAxADcAMgAzADMALgAzADYAMQA3ADIANgA1AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvYXJ1bmltYS9Eb3dubG9hZHMvMzYxNzIzMy4zNjE3MjY1LnBkZgAAEwABLwAAFQACAA7//wAAAAgADQAaACQAOgAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAGe},
	bdsk-url-1 = {https://doi.org/10.1145/3617233.3617265}}

@article{10539635,
	author = {Ntrougkas, Mariano V. and Gkalelis, Nikolaos and Mezaris, Vasileios},
	date-added = {2024-06-18 13:52:57 +0200},
	date-modified = {2024-06-18 13:52:57 +0200},
	doi = {10.1109/ACCESS.2024.3405788},
	journal = {IEEE Access},
	keywords = {Convolutional neural networks;Transformers;Task analysis;Computer architecture;Image classification;Computational modeling;Training;CNN;vision transformer;deep learning;explainable AI;model interpretability;attention},
	pages = {76880-76900},
	title = {T-TAME: Trainable Attention Mechanism for Explaining Convolutional Networks and Vision Transformers},
	volume = {12},
	year = {2024},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBoVC1UQU1FX1RyYWluYWJsZV9BdHRlbnRpb25fTWVjaGFuaXNtX2Zvcl9FeHBsYWluaW5nX0NvbnZvbHV0aW9uYWxfTmV0d29ya3NfYW5kX1Zpc2lvbl9UcmFuc2Zvcm1lcnMtMi5wZGZPEQKyAAAAAAKyAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADjXJPTQkQAAf////8fVC1UQU1FX1RyYWluYWJsZV9BI0ZGRkZGRkZGLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////+KXUS8AAAAAAAAAAAABAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgCCLzpVc2VyczphcnVuaW1hOkRvd25sb2FkczpULVRBTUVfVHJhaW5hYmxlX0F0dGVudGlvbl9NZWNoYW5pc21fZm9yX0V4cGxhaW5pbmdfQ29udm9sdXRpb25hbF9OZXR3b3Jrc19hbmRfVmlzaW9uX1RyYW5zZm9ybWVycy0yLnBkZgAOANIAaABUAC0AVABBAE0ARQBfAFQAcgBhAGkAbgBhAGIAbABlAF8AQQB0AHQAZQBuAHQAaQBvAG4AXwBNAGUAYwBoAGEAbgBpAHMAbQBfAGYAbwByAF8ARQB4AHAAbABhAGkAbgBpAG4AZwBfAEMAbwBuAHYAbwBsAHUAdABpAG8AbgBhAGwAXwBOAGUAdAB3AG8AcgBrAHMAXwBhAG4AZABfAFYAaQBzAGkAbwBuAF8AVAByAGEAbgBzAGYAbwByAG0AZQByAHMALQAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgCAVXNlcnMvYXJ1bmltYS9Eb3dubG9hZHMvVC1UQU1FX1RyYWluYWJsZV9BdHRlbnRpb25fTWVjaGFuaXNtX2Zvcl9FeHBsYWluaW5nX0NvbnZvbHV0aW9uYWxfTmV0d29ya3NfYW5kX1Zpc2lvbl9UcmFuc2Zvcm1lcnMtMi5wZGYAEwABLwAAFQACAA7//wAAAAgADQAaACQAjwAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAANF},
	bdsk-url-1 = {https://doi.org/10.1109/ACCESS.2024.3405788}}

@book{molnar2020interpretable,
	author = {Molnar, Christoph},
	date-added = {2024-06-15 03:05:20 +0200},
	date-modified = {2024-06-15 03:05:20 +0200},
	publisher = {Lulu. com},
	title = {Interpretable machine learning},
	year = {2020}}

@misc{lundberg2017unified,
	archiveprefix = {arXiv},
	author = {Scott Lundberg and Su-In Lee},
	date-added = {2024-06-15 02:34:34 +0200},
	date-modified = {2024-06-15 02:34:34 +0200},
	eprint = {1705.07874},
	primaryclass = {id='cs.AI' full_name='Artificial Intelligence' is_active=True alt_name=None in_archive='cs' is_general=False description='Covers all areas of AI except Vision, Robotics, Machine Learning, Multiagent Systems, and Computation and Language (Natural Language Processing), which have separate subject areas. In particular, includes Expert Systems, Theorem Proving (although this may overlap with Logic in Computer Science), Knowledge Representation, Planning, and Uncertainty in AI. Roughly includes material in ACM Subject Classes I.2.0, I.2.1, I.2.3, I.2.4, I.2.8, and I.2.11.'},
	title = {A Unified Approach to Interpreting Model Predictions},
	year = {2017}}

@article{bach2015pixel,
	author = {Bach, Sebastian and Binder, Alexander and Montavon, Gr{\'e}goire and Klauschen, Frederick and M{\"u}ller, Klaus-Robert and Samek, Wojciech},
	date-added = {2024-06-15 01:50:35 +0200},
	date-modified = {2024-06-15 01:50:35 +0200},
	journal = {PloS one},
	number = {7},
	pages = {e0130140},
	publisher = {Public Library of Science San Francisco, CA USA},
	title = {On pixel-wise explanations for non-linear classifier decisions by layer-wise relevance propagation},
	volume = {10},
	year = {2015}}

@article{Selvaraju_2019,
	author = {Selvaraju, Ramprasaath R. and Cogswell, Michael and Das, Abhishek and Vedantam, Ramakrishna and Parikh, Devi and Batra, Dhruv},
	date-added = {2024-06-15 00:43:43 +0200},
	date-modified = {2024-06-15 00:43:43 +0200},
	doi = {10.1007/s11263-019-01228-7},
	issn = {1573-1405},
	journal = {International Journal of Computer Vision},
	month = oct,
	number = {2},
	pages = {336--359},
	publisher = {Springer Science and Business Media LLC},
	title = {Grad-CAM: Visual Explanations from Deep Networks via Gradient-Based Localization},
	url = {http://dx.doi.org/10.1007/s11263-019-01228-7},
	volume = {128},
	year = {2019},
	bdsk-url-1 = {http://dx.doi.org/10.1007/s11263-019-01228-7}}

@inproceedings{panayotov2015librispeech,
	author = {Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
	booktitle = {2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
	date-added = {2024-06-14 20:57:20 +0200},
	date-modified = {2024-06-14 20:57:20 +0200},
	organization = {IEEE},
	pages = {5206--5210},
	title = {Librispeech: an asr corpus based on public domain audio books},
	year = {2015}}

@article{ardila2019common,
	author = {Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M and Weber, Gregor},
	date-added = {2024-06-14 20:56:23 +0200},
	date-modified = {2024-06-14 20:56:23 +0200},
	journal = {arXiv preprint arXiv:1912.06670},
	title = {Common voice: A massively-multilingual speech corpus},
	year = {2019}}

@article{baevski2020wav2vec,
	author = {Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
	date-added = {2024-06-14 20:17:07 +0200},
	date-modified = {2024-06-14 20:17:07 +0200},
	journal = {Advances in neural information processing systems},
	pages = {12449--12460},
	title = {wav2vec 2.0: A framework for self-supervised learning of speech representations},
	volume = {33},
	year = {2020}}

@inproceedings{radford2023robust,
	author = {Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
	booktitle = {International Conference on Machine Learning},
	date-added = {2024-06-14 20:13:52 +0200},
	date-modified = {2024-06-14 20:13:52 +0200},
	organization = {PMLR},
	pages = {28492--28518},
	title = {Robust speech recognition via large-scale weak supervision},
	year = {2023}}

@inproceedings{10389701,
	author = {Rekesh, Dima and Koluguri, Nithin Rao and Kriman, Samuel and Majumdar, Somshubra and Noroozi, Vahid and Huang, He and Hrinchuk, Oleksii and Puvvada, Krishna and Kumar, Ankur and Balam, Jagadeesh and Ginsburg, Boris},
	booktitle = {2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
	date-added = {2024-06-14 20:12:07 +0200},
	date-modified = {2024-06-14 20:12:07 +0200},
	doi = {10.1109/ASRU57964.2023.10389701},
	keywords = {Training;Computer architecture;Transformer cores;Transformers;Noise robustness;Decoding;Task analysis;speech recognition;speech translation;spoken language understanding},
	pages = {1-8},
	title = {Fast Conformer With Linearly Scalable Attention For Efficient Speech Recognition},
	year = {2023},
	bdsk-url-1 = {https://doi.org/10.1109/ASRU57964.2023.10389701}}

@inproceedings{sivasankaran2021explaining,
	author = {Sivasankaran, Sunit and Vincent, Emmanuel and Fohr, Dominique},
	booktitle = {INTERSPEECH 2021},
	date-added = {2024-06-14 07:39:07 +0200},
	date-modified = {2024-06-14 07:39:07 +0200},
	title = {Explaining deep learning models for speech enhancement},
	year = {2021}}

@article{pastor2023explaining,
	author = {Pastor, Eliana and Koudounas, Alkis and Attanasio, Giuseppe and Hovy, Dirk and Baralis, Elena},
	date-added = {2024-06-11 11:07:56 +0200},
	date-modified = {2024-06-11 11:07:56 +0200},
	journal = {arXiv preprint arXiv:2309.07733},
	title = {Explaining speech classification models via word-level audio segments and paralinguistic features},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhV1syXS5wZGZPEQEwAAAAAAEwAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADjXJPTQkQAAf////8HWzJdLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////+KNyfUAAAAAAAAAAAABAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgAhLzpVc2VyczphcnVuaW1hOkRvd25sb2FkczpbMl0ucGRmAAAOABAABwBbADIAXQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAH1VzZXJzL2FydW5pbWEvRG93bmxvYWRzL1syXS5wZGYAABMAAS8AABUAAgAO//8AAAAIAA0AGgAkACwAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAABYA==}}

@article{vitale2024exploring,
	author = {Vitale, Vincenzo Norman and Cutugno, Francesco and Origlia, Antonio and Coro, Gianpaolo},
	date-added = {2024-06-09 13:21:34 +0200},
	date-modified = {2024-06-09 13:21:34 +0200},
	journal = {Neural Computing and Applications},
	pages = {1--27},
	publisher = {Springer},
	title = {Exploring emergent syllables in end-to-end automatic speech recognizers through model explainability technique},
	year = {2024},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAWczAwNTIxLTAyNC0wOTQzNS0xLnBkZk8RAWoAAAAAAWoAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAONck9NCRAAB/////xZzMDA1MjEtMDI0LTA5NDM1LTEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////4otc/AAAAAAAAAAAAAEAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACADAvOlVzZXJzOmFydW5pbWE6RG93bmxvYWRzOnMwMDUyMS0wMjQtMDk0MzUtMS5wZGYADgAuABYAcwAwADAANQAyADEALQAwADIANAAtADAAOQA0ADMANQAtADEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAC5Vc2Vycy9hcnVuaW1hL0Rvd25sb2Fkcy9zMDA1MjEtMDI0LTA5NDM1LTEucGRmABMAAS8AABUAAgAO//8AAAAIAA0AGgAkAD0AAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAABqw==}}

@article{10190103,
	author = {Carofilis, Andr{\'e}s and Alegre, Enrique and Fidalgo, Eduardo and Fern{\'a}ndez-Robles, Laura},
	date-added = {2024-06-03 11:56:04 +0200},
	date-modified = {2024-06-03 11:56:04 +0200},
	doi = {10.1109/TASLP.2023.3297961},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	keywords = {Spectrogram;Speech processing;Task analysis;Hidden Markov models;Speech recognition;Acoustics;Training;Accent classification;Grad-CAM;Grad-Transfer;speech processing},
	pages = {2859-2871},
	title = {Improvement of Accent Classification Models Through Grad-Transfer From Spectrograms and Gradient-Weighted Class Activation Mapping},
	volume = {31},
	year = {2023},
	bdsk-url-1 = {https://doi.org/10.1109/TASLP.2023.3297961}}

@inproceedings{NEURIPS2023_c83bc020,
	author = {Deiseroth, Bj\"{o}rn and Deb, Mayukh and Weinbach, Samuel and Brack, Manuel and Schramowski, Patrick and Kersting, Kristian},
	booktitle = {Advances in Neural Information Processing Systems},
	date-added = {2024-05-26 21:23:25 +0200},
	date-modified = {2024-05-27 10:36:59 +0200},
	editor = {A. Oh and T. Naumann and A. Globerson and K. Saenko and M. Hardt and S. Levine},
	keywords = {model agnostic},
	organization = {Advances in Neural Information Processing Systems},
	pages = {63437--63460},
	publisher = {Curran Associates, Inc.},
	title = {ATMAN: Understanding Transformer Predictions Through Memory Efficient Attention Manipulation},
	url = {https://proceedings.neurips.cc/paper_files/paper/2023/file/c83bc020a020cdeb966ed10804619664-Paper-Conference.pdf},
	volume = {36},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxB9TmV1cklQUy0yMDIzLWF0bWFuLXVuZGVyc3RhbmRpbmctdHJhbnNmb3JtZXItcHJlZGljdGlvbnMtdGhyb3VnaC1tZW1vcnktZWZmaWNpZW50LWF0dGVudGlvbi1tYW5pcHVsYXRpb24tUGFwZXItQ29uZmVyZW5jZS5wZGZPEQMIAAAAAAMIAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADjXJPTQkQAAf////8fTmV1cklQUy0yMDIzLWF0bWFuI0ZGRkZGRkZGLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////+J5WPIAAAAAAAAAAAABAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgCXLzpVc2VyczphcnVuaW1hOkRvd25sb2FkczpOZXVySVBTLTIwMjMtYXRtYW4tdW5kZXJzdGFuZGluZy10cmFuc2Zvcm1lci1wcmVkaWN0aW9ucy10aHJvdWdoLW1lbW9yeS1lZmZpY2llbnQtYXR0ZW50aW9uLW1hbmlwdWxhdGlvbi1QYXBlci1Db25mZXJlbmNlLnBkZgAADgD8AH0ATgBlAHUAcgBJAFAAUwAtADIAMAAyADMALQBhAHQAbQBhAG4ALQB1AG4AZABlAHIAcwB0AGEAbgBkAGkAbgBnAC0AdAByAGEAbgBzAGYAbwByAG0AZQByAC0AcAByAGUAZABpAGMAdABpAG8AbgBzAC0AdABoAHIAbwB1AGcAaAAtAG0AZQBtAG8AcgB5AC0AZQBmAGYAaQBjAGkAZQBuAHQALQBhAHQAdABlAG4AdABpAG8AbgAtAG0AYQBuAGkAcAB1AGwAYQB0AGkAbwBuAC0AUABhAHAAZQByAC0AQwBvAG4AZgBlAHIAZQBuAGMAZQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAlVVzZXJzL2FydW5pbWEvRG93bmxvYWRzL05ldXJJUFMtMjAyMy1hdG1hbi11bmRlcnN0YW5kaW5nLXRyYW5zZm9ybWVyLXByZWRpY3Rpb25zLXRocm91Z2gtbWVtb3J5LWVmZmljaWVudC1hdHRlbnRpb24tbWFuaXB1bGF0aW9uLVBhcGVyLUNvbmZlcmVuY2UucGRmAAATAAEvAAAVAAIADv//AAAACAANABoAJACkAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAA7A=},
	bdsk-url-1 = {https://proceedings.neurips.cc/paper_files/paper/2023/file/c83bc020a020cdeb966ed10804619664-Paper-Conference.pdf}}

@inproceedings{9710570,
	author = {Chefer, Hila and Gur, Shir and Wolf, Lior},
	booktitle = {2021 IEEE/CVF International Conference on Computer Vision (ICCV)},
	date-added = {2024-05-26 21:17:59 +0200},
	date-modified = {2024-05-26 21:17:59 +0200},
	doi = {10.1109/ICCV48922.2021.00045},
	keywords = {Measurement;Computer vision;Visualization;Image segmentation;Computational modeling;Computer architecture;Object detection;Explainable AI;Vision + language},
	pages = {387-396},
	title = {Generic Attention-model Explainability for Interpreting Bi-Modal and Encoder-Decoder Transformers},
	year = {2021},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBlR2VuZXJpY19BdHRlbnRpb24tbW9kZWxfRXhwbGFpbmFiaWxpdHlfZm9yX0ludGVycHJldGluZ19CaS1Nb2RhbF9hbmRfRW5jb2Rlci1EZWNvZGVyX1RyYW5zZm9ybWVycy5wZGZPEQKoAAAAAAKoAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADjXJPTQkQAAf////8fR2VuZXJpY19BdHRlbnRpb24tI0ZGRkZGRkZGLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////+J5V6UAAAAAAAAAAAABAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgB/LzpVc2VyczphcnVuaW1hOkRvd25sb2FkczpHZW5lcmljX0F0dGVudGlvbi1tb2RlbF9FeHBsYWluYWJpbGl0eV9mb3JfSW50ZXJwcmV0aW5nX0JpLU1vZGFsX2FuZF9FbmNvZGVyLURlY29kZXJfVHJhbnNmb3JtZXJzLnBkZgAADgDMAGUARwBlAG4AZQByAGkAYwBfAEEAdAB0AGUAbgB0AGkAbwBuAC0AbQBvAGQAZQBsAF8ARQB4AHAAbABhAGkAbgBhAGIAaQBsAGkAdAB5AF8AZgBvAHIAXwBJAG4AdABlAHIAcAByAGUAdABpAG4AZwBfAEIAaQAtAE0AbwBkAGEAbABfAGEAbgBkAF8ARQBuAGMAbwBkAGUAcgAtAEQAZQBjAG8AZABlAHIAXwBUAHIAYQBuAHMAZgBvAHIAbQBlAHIAcwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAfVVzZXJzL2FydW5pbWEvRG93bmxvYWRzL0dlbmVyaWNfQXR0ZW50aW9uLW1vZGVsX0V4cGxhaW5hYmlsaXR5X2Zvcl9JbnRlcnByZXRpbmdfQmktTW9kYWxfYW5kX0VuY29kZXItRGVjb2Rlcl9UcmFuc2Zvcm1lcnMucGRmAAATAAEvAAAVAAIADv//AAAACAANABoAJACMAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAzg=},
	bdsk-url-1 = {https://doi.org/10.1109/ICCV48922.2021.00045}}

@article{bousselham2024legrad,
	author = {Bousselham, Walid and Boggust, Angie and Chaybouti, Sofian and Strobelt, Hendrik and Kuehne, Hilde},
	date-added = {2024-05-26 21:14:31 +0200},
	date-modified = {2024-05-26 21:14:31 +0200},
	journal = {arXiv preprint arXiv:2404.03214},
	title = {LeGrad: An Explainability Method for Vision Transformers via Feature Formation Sensitivity},
	year = {2024}}

@inproceedings{10204354,
	annote = {Explainability for a method called pruning, which maked the models hardware friendly by removing the least important parameters in pre-trained models },
	author = {Yu, Lu and Xiang, Wei},
	booktitle = {2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	date-added = {2024-05-26 21:11:14 +0200},
	date-modified = {2024-05-27 10:34:12 +0200},
	doi = {10.1109/CVPR52729.2023.02333},
	keywords = {Not,Degradation;Computer vision;Measurement units;Computational modeling;Simulation;Memory management;Transformers;Explainable computer vision},
	organization = {2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	pages = {24355-24363},
	publisher = {2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
	title = {X-Pruner: eXplainable Pruning for Vision Transformers},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxA4WC1QcnVuZXJfZVhwbGFpbmFibGVfUHJ1bmluZ19mb3JfVmlzaW9uX1RyYW5zZm9ybWVycy5wZGZPEQHyAAAAAAHyAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADjXJPTQkQAAf////8fWC1QcnVuZXJfZVhwbGFpbmFiI0ZGRkZGRkZGLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////+J5VgEAAAAAAAAAAAABAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgBSLzpVc2VyczphcnVuaW1hOkRvd25sb2FkczpYLVBydW5lcl9lWHBsYWluYWJsZV9QcnVuaW5nX2Zvcl9WaXNpb25fVHJhbnNmb3JtZXJzLnBkZgAOAHIAOABYAC0AUAByAHUAbgBlAHIAXwBlAFgAcABsAGEAaQBuAGEAYgBsAGUAXwBQAHIAdQBuAGkAbgBnAF8AZgBvAHIAXwBWAGkAcwBpAG8AbgBfAFQAcgBhAG4AcwBmAG8AcgBtAGUAcgBzAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBQVXNlcnMvYXJ1bmltYS9Eb3dubG9hZHMvWC1QcnVuZXJfZVhwbGFpbmFibGVfUHJ1bmluZ19mb3JfVmlzaW9uX1RyYW5zZm9ybWVycy5wZGYAEwABLwAAFQACAA7//wAAAAgADQAaACQAXwAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAJV},
	bdsk-url-1 = {https://doi.org/10.1109/CVPR52729.2023.02333}}

@inproceedings{pmlr-v162-ali22a,
	abstract = {Transformers have become an important workhorse of machine learning, with numerous applications. This necessitates the development of reliable methods for increasing their transparency. Multiple interpretability methods, often based on gradient information, have been proposed. We show that the gradient in a Transformer reflects the function only locally, and thus fails to reliably identify the contribution of input features to the prediction. We identify Attention Heads and LayerNorm as main reasons for such unreliable explanations and propose a more stable way for propagation through these layers. Our proposal, which can be seen as a proper extension of the well-established LRP method to Transformers, is shown both theoretically and empirically to overcome the deficiency of a simple gradient-based approach, and achieves state-of-the-art explanation performance on a broad range of Transformer models and datasets.},
	author = {Ali, Ameen and Schnake, Thomas and Eberle, Oliver and Montavon, Gr{\'e}goire and M{\"u}ller, Klaus-Robert and Wolf, Lior},
	booktitle = {Proceedings of the 39th International Conference on Machine Learning},
	date-added = {2024-05-26 21:09:27 +0200},
	date-modified = {2024-05-26 21:10:35 +0200},
	editor = {Chaudhuri, Kamalika and Jegelka, Stefanie and Song, Le and Szepesvari, Csaba and Niu, Gang and Sabato, Sivan},
	month = {17--23 Jul},
	organization = {Proceedings of the 39th International Conference on Machine Learning},
	pages = {435--451},
	pdf = {https://proceedings.mlr.press/v162/ali22a/ali22a.pdf},
	publisher = {PMLR},
	series = {Proceedings of Machine Learning Research},
	title = {{XAI} for Transformers: Better Explanations through Conservative Propagation},
	url = {https://proceedings.mlr.press/v162/ali22a.html},
	volume = {162},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhWmFsaTIyYS5wZGZPEQE6AAAAAAE6AAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADjXJPTQkQAAf////8KYWxpMjJhLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////+J5VagAAAAAAAAAAAABAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgAkLzpVc2VyczphcnVuaW1hOkRvd25sb2FkczphbGkyMmEucGRmAA4AFgAKAGEAbABpADIAMgBhAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAiVXNlcnMvYXJ1bmltYS9Eb3dubG9hZHMvYWxpMjJhLnBkZgATAAEvAAAVAAIADv//AAAACAANABoAJAAvAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAW0=},
	bdsk-url-1 = {https://proceedings.mlr.press/v162/ali22a.html}}

@article{computers13040092,
	abstract = {An increasing demand for model explainability has accompanied the widespread adoption of transformers in various fields of applications. In this paper, we conduct a survey of the existing literature on the explainability of transformers. We provide a taxonomy of methods based on the combination of transformer components that are leveraged to arrive at the explanation. For each method, we describe its mechanism and survey its applications. We find out that attention-based methods, both alone and in conjunction with activation-based and gradient-based methods, are the most employed ones. A growing attention is also devoted to the deployment of visualization techniques to help the explanation process.},
	article-number = {92},
	author = {Fantozzi, Paolo and Naldi, Maurizio},
	date-added = {2024-05-26 21:06:38 +0200},
	date-modified = {2024-05-26 21:07:07 +0200},
	doi = {10.3390/computers13040092},
	issn = {2073-431X},
	journal = {Computers MDPI},
	number = {4},
	title = {The Explainability of Transformers: Current Status and Directions},
	url = {https://www.mdpi.com/2073-431X/13/4/92},
	volume = {13},
	year = {2024},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAZY29tcHV0ZXJzLTEzLTAwMDkyLXYyLnBkZk8RAXgAAAAAAXgAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAONck9NCRAAB/////xljb21wdXRlcnMtMTMtMDAwOTItdjIucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////4nlVJAAAAAAAAAAAAAEAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACADMvOlVzZXJzOmFydW5pbWE6RG93bmxvYWRzOmNvbXB1dGVycy0xMy0wMDA5Mi12Mi5wZGYAAA4ANAAZAGMAbwBtAHAAdQB0AGUAcgBzAC0AMQAzAC0AMAAwADAAOQAyAC0AdgAyAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAxVXNlcnMvYXJ1bmltYS9Eb3dubG9hZHMvY29tcHV0ZXJzLTEzLTAwMDkyLXYyLnBkZgAAEwABLwAAFQACAA7//wAAAAgADQAaACQAQAAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAG8},
	bdsk-url-1 = {https://www.mdpi.com/2073-431X/13/4/92}}

@article{gulati2020conformer,
	author = {Gulati, Anmol and Qin, James and Chiu, Chung-Cheng and Parmar, Niki and Zhang, Yu and Yu, Jiahui and Han, Wei and Wang, Shibo and Zhang, Zhengdong and Wu, Yonghui and others},
	date-added = {2024-05-24 11:43:01 +0200},
	date-modified = {2024-05-24 11:43:01 +0200},
	journal = {arXiv preprint arXiv:2005.08100},
	title = {Conformer: Convolution-augmented transformer for speech recognition},
	year = {2020},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAQMjAwNS4wODEwMHYxLnBkZk8RAVIAAAAAAVIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAONck9NCRAAB/////xAyMDA1LjA4MTAwdjEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////4nYtnAAAAAAAAAAAAAEAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACACovOlVzZXJzOmFydW5pbWE6RG93bmxvYWRzOjIwMDUuMDgxMDB2MS5wZGYADgAiABAAMgAwADAANQAuADAAOAAxADAAMAB2ADEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAChVc2Vycy9hcnVuaW1hL0Rvd25sb2Fkcy8yMDA1LjA4MTAwdjEucGRmABMAAS8AABUAAgAO//8AAAAIAA0AGgAkADcAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAABjQ==}}

@inproceedings{10095896,
	author = {Omachi, Motoi and Yan, Brian and Dalmia, Siddharth and Fujita, Yuya and Watanabe, Shinji},
	booktitle = {ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	date-added = {2024-05-16 12:37:13 +0200},
	date-modified = {2024-05-16 12:37:13 +0200},
	doi = {10.1109/ICASSP49357.2023.10095896},
	keywords = {Out of order;Closed box;Signal processing;Real-time systems;Acoustics;Task analysis;Speech processing;speech recognition;speech-to-text translation},
	pages = {1-5},
	title = {Align, Write, Re-Order: Explainable End-to-End Speech Translation via Operation Sequence Generation},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBkQWxpZ25fV3JpdGVfUmUtT3JkZXJfRXhwbGFpbmFibGVfRW5kLXRvLUVuZF9TcGVlY2hfVHJhbnNsYXRpb25fdmlhX09wZXJhdGlvbl9TZXF1ZW5jZV9HZW5lcmF0aW9uLnBkZk8RAqIAAAAAAqIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAONck9NCRAAB/////x9BbGlnbl9Xcml0ZV9SZS1PcmQjRkZGRkZGRkYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////4muulQAAAAAAAAAAAAEAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACAH4vOlVzZXJzOmFydW5pbWE6RG93bmxvYWRzOkFsaWduX1dyaXRlX1JlLU9yZGVyX0V4cGxhaW5hYmxlX0VuZC10by1FbmRfU3BlZWNoX1RyYW5zbGF0aW9uX3ZpYV9PcGVyYXRpb25fU2VxdWVuY2VfR2VuZXJhdGlvbi5wZGYADgDKAGQAQQBsAGkAZwBuAF8AVwByAGkAdABlAF8AUgBlAC0ATwByAGQAZQByAF8ARQB4AHAAbABhAGkAbgBhAGIAbABlAF8ARQBuAGQALQB0AG8ALQBFAG4AZABfAFMAcABlAGUAYwBoAF8AVAByAGEAbgBzAGwAYQB0AGkAbwBuAF8AdgBpAGEAXwBPAHAAZQByAGEAdABpAG8AbgBfAFMAZQBxAHUAZQBuAGMAZQBfAEcAZQBuAGUAcgBhAHQAaQBvAG4ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAHxVc2Vycy9hcnVuaW1hL0Rvd25sb2Fkcy9BbGlnbl9Xcml0ZV9SZS1PcmRlcl9FeHBsYWluYWJsZV9FbmQtdG8tRW5kX1NwZWVjaF9UcmFuc2xhdGlvbl92aWFfT3BlcmF0aW9uX1NlcXVlbmNlX0dlbmVyYXRpb24ucGRmABMAAS8AABUAAgAO//8AAAAIAA0AGgAkAIsAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAADMQ==},
	bdsk-url-1 = {https://doi.org/10.1109/ICASSP49357.2023.10095896}}

@inproceedings{kumar2021towards,
	author = {Kumar, Puneet and Kaushik, Vishesh and Raman, Balasubramanian},
	booktitle = {Interspeech},
	date-added = {2024-05-16 11:23:40 +0200},
	date-modified = {2024-05-16 11:23:40 +0200},
	pages = {1748--1752},
	title = {Towards the Explainability of Multimodal Speech Emotion Recognition.},
	year = {2021},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAYa3VtYXIyMWRfaW50ZXJzcGVlY2gucGRmTxEBcgAAAAABcgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAA41yT00JEAAH/////GGt1bWFyMjFkX2ludGVyc3BlZWNoLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/////ia63aAAAAAAAAAAAAAQACAAAKIGN1AAAAAAAAAAAAAAAAAAlEb3dubG9hZHMAAAIAMi86VXNlcnM6YXJ1bmltYTpEb3dubG9hZHM6a3VtYXIyMWRfaW50ZXJzcGVlY2gucGRmAA4AMgAYAGsAdQBtAGEAcgAyADEAZABfAGkAbgB0AGUAcgBzAHAAZQBlAGMAaAAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAMFVzZXJzL2FydW5pbWEvRG93bmxvYWRzL2t1bWFyMjFkX2ludGVyc3BlZWNoLnBkZgATAAEvAAAVAAIADv//AAAACAANABoAJAA/AAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAbU=}}

@article{9391727,
	author = {Joshi, Gargi and Walambe, Rahee and Kotecha, Ketan},
	date-added = {2024-05-16 11:12:27 +0200},
	date-modified = {2024-05-16 11:12:27 +0200},
	doi = {10.1109/ACCESS.2021.3070212},
	journal = {IEEE Access},
	keywords = {Task analysis;Visualization;Neural networks;Artificial intelligence;Biomedical imaging;Deep learning;Data models;Deep multimodal learning;explainable AI;interpretability;survey;trends;vision and language research;XAI},
	pages = {59800-59821},
	title = {A Review on Explainability in Multimodal Deep Neural Nets},
	volume = {9},
	year = {2021},
	bdsk-url-1 = {https://doi.org/10.1109/ACCESS.2021.3070212}}

@article{kashefi2023explainability,
	author = {Kashefi, Rojina and Barekatain, Leili and Sabokrou, Mohammad and Aghaeipoor, Fatemeh},
	date-added = {2024-05-07 14:15:09 +0200},
	date-modified = {2024-05-07 14:15:09 +0200},
	journal = {arXiv preprint arXiv:2311.06786},
	title = {Explainability of Vision Transformers: A Comprehensive Review and New Perspectives},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAQMjMxMS4wNjc4NnYxLnBkZk8RAVIAAAAAAVIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAONck9NCRAAB/////xAyMzExLjA2Nzg2djEucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////4oTNXwAAAAAAAAAAAAEAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACACovOlVzZXJzOmFydW5pbWE6RG93bmxvYWRzOjIzMTEuMDY3ODZ2MS5wZGYADgAiABAAMgAzADEAMQAuADAANgA3ADgANgB2ADEALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAChVc2Vycy9hcnVuaW1hL0Rvd25sb2Fkcy8yMzExLjA2Nzg2djEucGRmABMAAS8AABUAAgAO//8AAAAIAA0AGgAkADcAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAABjQ==}}

@article{niu2024r,
	author = {Niu, Yingjie and Ding, Ming and Ge, Maoning and Karlsson, Robin and Zhang, Yuxiao and Carballo, Alexander and Takeda, Kazuya},
	date-added = {2024-05-06 15:09:28 +0200},
	date-modified = {2024-05-06 15:09:28 +0200},
	journal = {Sensors},
	number = {9},
	pages = {2695},
	publisher = {MDPI},
	title = {R-cut: Enhancing explainability in vision transformers with relationship weighted out and cut},
	volume = {24},
	year = {2024},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAUc2Vuc29ycy0yNC0wMjY5NS5wZGZPEQFiAAAAAAFiAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADjXJPTQkQAAf////8Uc2Vuc29ycy0yNC0wMjY5NS5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////+JeozsAAAAAAAAAAAABAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgAuLzpVc2VyczphcnVuaW1hOkRvd25sb2FkczpzZW5zb3JzLTI0LTAyNjk1LnBkZgAOACoAFABzAGUAbgBzAG8AcgBzAC0AMgA0AC0AMAAyADYAOQA1AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgAsVXNlcnMvYXJ1bmltYS9Eb3dubG9hZHMvc2Vuc29ycy0yNC0wMjY5NS5wZGYAEwABLwAAFQACAA7//wAAAAgADQAaACQAOwAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAGh},
	bdsk-file-2 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxASMjMwNy4wOTA1MHYxLTIucGRmTxEBWgAAAAABWgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAA41yT00JEAAH/////EjIzMDcuMDkwNTB2MS0yLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/////iXqLTAAAAAAAAAAAAAQACAAAKIGN1AAAAAAAAAAAAAAAAAAlEb3dubG9hZHMAAAIALC86VXNlcnM6YXJ1bmltYTpEb3dubG9hZHM6MjMwNy4wOTA1MHYxLTIucGRmAA4AJgASADIAMwAwADcALgAwADkAMAA1ADAAdgAxAC0AMgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAKlVzZXJzL2FydW5pbWEvRG93bmxvYWRzLzIzMDcuMDkwNTB2MS0yLnBkZgATAAEvAAAVAAIADv//AAAACAANABoAJAA5AAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAZc=}}

@inproceedings{9971881,
	author = {Shah, Raj and Dave, Bhavi and Parekh, Nirali and Srivastava, Kriti},
	booktitle = {2022 IEEE 3rd Global Conference for Advancement in Technology (GCAT)},
	date-added = {2024-04-24 12:28:57 +0200},
	date-modified = {2024-04-24 12:28:57 +0200},
	doi = {10.1109/GCAT55367.2022.9971881},
	keywords = {Productivity;Deep learning;Parkinson's disease;Neural networks;Closed box;Predictive models;Prediction algorithms;Parkinsons Disease;Explainable AI;Deep Learning;Spectrograms;Convolutional Neural Network},
	pages = {1-6},
	title = {Parkinson's Disease Detection - An Interpretable Approach to Temporal Audio Classification},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1109/GCAT55367.2022.9971881}}

@article{10413597,
	author = {Parekh, Jayneel and Parekh, Sanjeel and Mozharovskyi, Pavlo and Richard, Ga{\"e}l and d'Alch{\'e}-Buc, Florence},
	date-added = {2024-04-24 12:26:02 +0200},
	date-modified = {2024-04-24 12:27:40 +0200},
	doi = {10.1109/TASLP.2024.3358049},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	keywords = {NMF, Task analysis;Dictionaries;Spectrogram;Training;Time-frequency analysis;Speech processing;Prototypes;Audio interpretability;explainability;by-design interpretable models;audio convolutional networks;non-negative matrix factorization},
	pages = {1392-1405},
	title = {Tackling Interpretability in Audio Classification Networks With Non-negative Matrix Factorization},
	volume = {32},
	year = {2024},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBlVGFja2xpbmdfSW50ZXJwcmV0YWJpbGl0eV9pbl9BdWRpb19DbGFzc2lmaWNhdGlvbl9OZXR3b3Jrc19XaXRoX05vbi1uZWdhdGl2ZV9NYXRyaXhfRmFjdG9yaXphdGlvbi5wZGZPEQKoAAAAAAKoAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADjXJPTQkQAAf////8fVGFja2xpbmdfSW50ZXJwcmV0I0ZGRkZGRkZGLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////+JxPGsAAAAAAAAAAAABAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgB/LzpVc2VyczphcnVuaW1hOkRvd25sb2FkczpUYWNrbGluZ19JbnRlcnByZXRhYmlsaXR5X2luX0F1ZGlvX0NsYXNzaWZpY2F0aW9uX05ldHdvcmtzX1dpdGhfTm9uLW5lZ2F0aXZlX01hdHJpeF9GYWN0b3JpemF0aW9uLnBkZgAADgDMAGUAVABhAGMAawBsAGkAbgBnAF8ASQBuAHQAZQByAHAAcgBlAHQAYQBiAGkAbABpAHQAeQBfAGkAbgBfAEEAdQBkAGkAbwBfAEMAbABhAHMAcwBpAGYAaQBjAGEAdABpAG8AbgBfAE4AZQB0AHcAbwByAGsAcwBfAFcAaQB0AGgAXwBOAG8AbgAtAG4AZQBnAGEAdABpAHYAZQBfAE0AYQB0AHIAaQB4AF8ARgBhAGMAdABvAHIAaQB6AGEAdABpAG8AbgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAfVVzZXJzL2FydW5pbWEvRG93bmxvYWRzL1RhY2tsaW5nX0ludGVycHJldGFiaWxpdHlfaW5fQXVkaW9fQ2xhc3NpZmljYXRpb25fTmV0d29ya3NfV2l0aF9Ob24tbmVnYXRpdmVfTWF0cml4X0ZhY3Rvcml6YXRpb24ucGRmAAATAAEvAAAVAAIADv//AAAACAANABoAJACMAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAzg=},
	bdsk-url-1 = {https://doi.org/10.1109/TASLP.2024.3358049}}

@inproceedings{10447390,
	author = {Akman, Alican and Schuller, Bj{\"o}rn W.},
	booktitle = {ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	date-added = {2024-04-24 12:24:43 +0200},
	date-modified = {2024-04-24 12:27:27 +0200},
	doi = {10.1109/ICASSP48485.2024.10447390},
	keywords = {NMF,Training;Visualization;Computational modeling;Predictive models;Signal processing;Transformers;Reliability;Audio Explainability;Computer Audition;Audio Transformers;Explainable Artificial Intelligence},
	pages = {7015-7019},
	title = {AttHear: Explaining Audio Transformers Using Attention-Aware NMF},
	year = {2024},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBDQXR0SGVhcl9FeHBsYWluaW5nX0F1ZGlvX1RyYW5zZm9ybWVyc19Vc2luZ19BdHRlbnRpb24tQXdhcmVfTk1GLnBkZk8RAiAAAAAAAiAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAONck9NCRAAB/////x9BdHRIZWFyX0V4cGxhaW5pbmcjRkZGRkZGRkYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////4k6qmQAAAAAAAAAAAAEAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACAF0vOlVzZXJzOmFydW5pbWE6RG93bmxvYWRzOkF0dEhlYXJfRXhwbGFpbmluZ19BdWRpb19UcmFuc2Zvcm1lcnNfVXNpbmdfQXR0ZW50aW9uLUF3YXJlX05NRi5wZGYAAA4AiABDAEEAdAB0AEgAZQBhAHIAXwBFAHgAcABsAGEAaQBuAGkAbgBnAF8AQQB1AGQAaQBvAF8AVAByAGEAbgBzAGYAbwByAG0AZQByAHMAXwBVAHMAaQBuAGcAXwBBAHQAdABlAG4AdABpAG8AbgAtAEEAdwBhAHIAZQBfAE4ATQBGAC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgBbVXNlcnMvYXJ1bmltYS9Eb3dubG9hZHMvQXR0SGVhcl9FeHBsYWluaW5nX0F1ZGlvX1RyYW5zZm9ybWVyc19Vc2luZ19BdHRlbnRpb24tQXdhcmVfTk1GLnBkZgAAEwABLwAAFQACAA7//wAAAAgADQAaACQAagAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAKO},
	bdsk-url-1 = {https://doi.org/10.1109/ICASSP48485.2024.10447390}}

@inproceedings{9914699,
	author = {Bicer, H. Nazim and G{\"o}tz, Philipp and Tuna, Cagdas and Habets, Emanu{\"e}l A. P.},
	booktitle = {2022 International Workshop on Acoustic Signal Enhancement (IWAENC)},
	date-added = {2024-04-24 12:05:22 +0200},
	date-modified = {2024-04-24 12:05:22 +0200},
	doi = {10.1109/IWAENC53105.2022.9914699},
	keywords = {Time-frequency analysis;Image analysis;Computational modeling;Decision making;Neural networks;Computer architecture;Predictive models;explainable artificial intelligence;acoustic scene classification;convolutional neural networks;ResNet;spectrogram;guided backpropagation;Grad-CAM;interpretability},
	pages = {1-5},
	title = {Explainable Acoustic Scene Classification: Making Decisions Audible},
	year = {2022},
	bdsk-url-1 = {https://doi.org/10.1109/IWAENC53105.2022.9914699}}

@inproceedings{6839284,
	author = {Chandrasekar, Purnima and Chapaneri, Santosh and Jayaswal, Deepak},
	booktitle = {2014 International Conference on Circuits, Systems, Communication and Information Technology Applications (CSCITA)},
	date-added = {2024-04-22 14:59:46 +0200},
	date-modified = {2024-04-22 15:00:00 +0200},
	doi = {10.1109/CSCITA.2014.6839284},
	keywords = {ASR, survey, Feature extraction;Speech;Speech recognition;Emotion recognition;Databases;Hidden Markov models;Mel frequency cepstral coefficient;feature extraction;dimensionality reduction;feature classification},
	pages = {341-346},
	title = {Automatic Speech Emotion Recognition: A survey},
	year = {2014},
	bdsk-url-1 = {https://doi.org/10.1109/CSCITA.2014.6839284}}

@article{10301513,
	author = {Prabhavalkar, Rohit and Hori, Takaaki and Sainath, Tara N. and Schl{\"u}ter, Ralf and Watanabe, Shinji},
	date-added = {2024-04-22 14:58:25 +0200},
	date-modified = {2024-04-22 14:58:41 +0200},
	doi = {10.1109/TASLP.2023.3328283},
	journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
	keywords = {ASR, survey , Hidden Markov models;Training;Data models;Acoustics;Task analysis;Deep learning;Decoding;End-to-end;automatic speech recognition},
	pages = {325-351},
	title = {End-to-End Speech Recognition: A Survey},
	volume = {32},
	year = {2024},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAqRW5kLXRvLUVuZF9TcGVlY2hfUmVjb2duaXRpb25fQV9TdXJ2ZXkucGRmTxEBugAAAAABugACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAA41yT00JEAAH/////H0VuZC10by1FbmRfU3BlZWNoXyNGRkZGRkZGRi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/////iTqu4AAAAAAAAAAAAAQACAAAKIGN1AAAAAAAAAAAAAAAAAAlEb3dubG9hZHMAAAIARC86VXNlcnM6YXJ1bmltYTpEb3dubG9hZHM6RW5kLXRvLUVuZF9TcGVlY2hfUmVjb2duaXRpb25fQV9TdXJ2ZXkucGRmAA4AVgAqAEUAbgBkAC0AdABvAC0ARQBuAGQAXwBTAHAAZQBlAGMAaABfAFIAZQBjAG8AZwBuAGkAdABpAG8AbgBfAEEAXwBTAHUAcgB2AGUAeQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAQlVzZXJzL2FydW5pbWEvRG93bmxvYWRzL0VuZC10by1FbmRfU3BlZWNoX1JlY29nbml0aW9uX0FfU3VydmV5LnBkZgATAAEvAAAVAAIADv//AAAACAANABoAJABRAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAg8=},
	bdsk-url-1 = {https://doi.org/10.1109/TASLP.2023.3328283}}

@article{electronics10070850,
	abstract = {Deep learning models have improved cutting-edge technologies in many research areas, but their black-box structure makes it difficult to understand their inner workings and the rationale behind their predictions. This may lead to unintended effects, such as being susceptible to adversarial attacks or the reinforcement of biases. There is still a lack of research in the audio domain, despite the increasing interest in developing deep learning models that provide explanations of their decisions. To reduce this gap, we propose a novel interpretable deep learning model for automatic sound classification, which explains its predictions based on the similarity of the input to a set of learned prototypes in a latent space. We leverage domain knowledge by designing a frequency-dependent similarity measure and by considering different time-frequency resolutions in the feature space. The proposed model achieves results that are comparable to that of the state-of-the-art methods in three different sound classification tasks involving speech, music, and environmental audio. In addition, we present two automatic methods to prune the proposed model that exploit its interpretability. Our system is open source and it is accompanied by a web application for the manual editing of the model, which allows for a human-in-the-loop debugging approach.},
	article-number = {850},
	author = {Zinemanas, Pablo and Rocamora, Mart{\'\i}n and Miron, Marius and Font, Frederic and Serra, Xavier},
	date-added = {2024-04-14 17:31:28 +0200},
	date-modified = {2024-04-14 17:31:28 +0200},
	doi = {10.3390/electronics10070850},
	issn = {2079-9292},
	journal = {Electronics},
	number = {7},
	title = {An Interpretable Deep Learning Model for Automatic Sound Classification},
	url = {https://www.mdpi.com/2079-9292/10/7/850},
	volume = {10},
	year = {2021},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAbZWxlY3Ryb25pY3MtMTAtMDA4NTAtdjIucGRmTxEBgAAAAAABgAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAA41yT00JEAAH/////G2VsZWN0cm9uaWNzLTEwLTAwODUwLXYyLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/////iQcN3AAAAAAAAAAAAAQACAAAKIGN1AAAAAAAAAAAAAAAAAAlEb3dubG9hZHMAAAIANS86VXNlcnM6YXJ1bmltYTpEb3dubG9hZHM6ZWxlY3Ryb25pY3MtMTAtMDA4NTAtdjIucGRmAAAOADgAGwBlAGwAZQBjAHQAcgBvAG4AaQBjAHMALQAxADAALQAwADAAOAA1ADAALQB2ADIALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASADNVc2Vycy9hcnVuaW1hL0Rvd25sb2Fkcy9lbGVjdHJvbmljcy0xMC0wMDg1MC12Mi5wZGYAABMAAS8AABUAAgAO//8AAAAIAA0AGgAkAEIAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAABxg==}}

@article{becker2024audiomnist,
	author = {Becker, S{\"o}ren and Vielhaben, Johanna and Ackermann, Marcel and M{\"u}ller, Klaus-Robert and Lapuschkin, Sebastian and Samek, Wojciech},
	date-added = {2024-04-14 17:30:22 +0200},
	date-modified = {2024-04-14 17:30:22 +0200},
	journal = {Journal of the Franklin Institute},
	number = {1},
	pages = {418--428},
	publisher = {Elsevier},
	title = {AudioMNIST: Exploring Explainable Artificial Intelligence for audio analysis on a simple benchmark},
	volume = {361},
	year = {2024},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAPMTgwNy4wMzQxOC5odG1sTxEBUAAAAAABUAACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAA41yT00JEAAH/////DzE4MDcuMDM0MTguaHRtbAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/////iQcTwAAAAAAAAAAAAAQACAAAKIGN1AAAAAAAAAAAAAAAAAAlEb3dubG9hZHMAAAIAKS86VXNlcnM6YXJ1bmltYTpEb3dubG9hZHM6MTgwNy4wMzQxOC5odG1sAAAOACAADwAxADgAMAA3AC4AMAAzADQAMQA4AC4AaAB0AG0AbAAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASACdVc2Vycy9hcnVuaW1hL0Rvd25sb2Fkcy8xODA3LjAzNDE4Lmh0bWwAABMAAS8AABUAAgAO//8AAAAIAA0AGgAkADYAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAABig==}}

@article{app12083926,
	abstract = {Fake media, generated by methods such as deepfakes, have become indistinguishable from real media, but their detection has not improved at the same pace. Furthermore, the absence of interpretability on deepfake detection models makes their reliability questionable. In this paper, we present a human perception level of interpretability for deepfake audio detection. Based on their characteristics, we implement several explainable artificial intelligence (XAI) methods used for image classification on an audio-related task. In addition, by examining the human cognitive process of XAI on image classification, we suggest the use of a corresponding data format for providing interpretability. Using this novel concept, a fresh interpretation using attribution scores can be provided.},
	article-number = {3926},
	author = {Lim, Suk-Young and Chae, Dong-Kyu and Lee, Sang-Chul},
	date-added = {2024-04-14 17:28:01 +0200},
	date-modified = {2024-04-14 17:28:01 +0200},
	doi = {10.3390/app12083926},
	issn = {2076-3417},
	journal = {Applied Sciences},
	number = {8},
	title = {Detecting Deepfake Voice Using Explainable Deep Learning Techniques},
	url = {https://www.mdpi.com/2076-3417/12/8/3926},
	volume = {12},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxAXYXBwbHNjaS0xMi0wMzkyNi12My5wZGZPEQFwAAAAAAFwAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADjXJPTQkQAAf////8XYXBwbHNjaS0xMi0wMzkyNi12My5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////+JBwrAAAAAAAAAAAAABAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgAxLzpVc2VyczphcnVuaW1hOkRvd25sb2FkczphcHBsc2NpLTEyLTAzOTI2LXYzLnBkZgAADgAwABcAYQBwAHAAbABzAGMAaQAtADEAMgAtADAAMwA5ADIANgAtAHYAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAL1VzZXJzL2FydW5pbWEvRG93bmxvYWRzL2FwcGxzY2ktMTItMDM5MjYtdjMucGRmAAATAAEvAAAVAAIADv//AAAACAANABoAJAA+AAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAbI=}}

@inproceedings{10446648,
	author = {Mariotte, Th{\'e}o and Almud{\'e}var, Antonio and Tahon, Marie and Ortega, Alfonso},
	booktitle = {ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	date-added = {2024-04-14 17:26:22 +0200},
	date-modified = {2024-04-24 12:27:09 +0200},
	doi = {10.1109/ICASSP48485.2024.10446648},
	keywords = {NMF,Voice activity detection;Explainable AI;Frequency-domain analysis;Decision making;Prototypes;Closed box;Signal processing;multilabel audio segmentation;explainability;non-negative matrix factorization;music detection;speech detection},
	pages = {531-535},
	title = {An Explainable Proxy Model for Multilabel Audio Segmentation},
	year = {2024},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBAQW5fRXhwbGFpbmFibGVfUHJveHlfTW9kZWxfZm9yX011bHRpbGFiZWxfQXVkaW9fU2VnbWVudGF0aW9uLnBkZk8RAhIAAAAAAhIAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAONck9NCRAAB/////x9Bbl9FeHBsYWluYWJsZV9Qcm8jRkZGRkZGRkYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////4kHCSgAAAAAAAAAAAAEAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACAFovOlVzZXJzOmFydW5pbWE6RG93bmxvYWRzOkFuX0V4cGxhaW5hYmxlX1Byb3h5X01vZGVsX2Zvcl9NdWx0aWxhYmVsX0F1ZGlvX1NlZ21lbnRhdGlvbi5wZGYADgCCAEAAQQBuAF8ARQB4AHAAbABhAGkAbgBhAGIAbABlAF8AUAByAG8AeAB5AF8ATQBvAGQAZQBsAF8AZgBvAHIAXwBNAHUAbAB0AGkAbABhAGIAZQBsAF8AQQB1AGQAaQBvAF8AUwBlAGcAbQBlAG4AdABhAHQAaQBvAG4ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAFhVc2Vycy9hcnVuaW1hL0Rvd25sb2Fkcy9Bbl9FeHBsYWluYWJsZV9Qcm94eV9Nb2RlbF9mb3JfTXVsdGlsYWJlbF9BdWRpb19TZWdtZW50YXRpb24ucGRmABMAAS8AABUAAgAO//8AAAAIAA0AGgAkAGcAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACfQ==},
	bdsk-url-1 = {https://doi.org/10.1109/ICASSP48485.2024.10446648}}

@inproceedings{10094635,
	author = {Wu, Xiaoliang and Bell, Peter and Rajan, Ajitha},
	booktitle = {ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	date-added = {2024-04-14 17:19:39 +0200},
	date-modified = {2024-04-14 17:19:39 +0200},
	doi = {10.1109/ICASSP49357.2023.10094635},
	keywords = {Adaptation models;Neural networks;Machine learning;Signal processing;Quality assessment;Internet;Speech processing;Explanation;Automatic Speech Recognition},
	pages = {1-5},
	title = {Explanations for Automatic Speech Recognition},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBjLi4vTGlicmFyeS9Nb2JpbGUgRG9jdW1lbnRzL2NvbX5hcHBsZX5DbG91ZERvY3MvUm5EL1BhcGVycy8yMDdlMWI5Yy1lZDA3LTRjN2UtOTdlNC01MzVmMzA1YjRjMWUucGRmTxECCgAAAAACCgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAA41yT00JEAAH/////HzIwN2UxYjljLWVkMDctNGM3ZSNGRkZGRkZGRi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/////iAmHqAAAAAAAAAAAAAQAGAAAKIGN1AAAAAAAAAAAAAAAAAAZQYXBlcnMAAgBwLzpVc2VyczphcnVuaW1hOkxpYnJhcnk6TW9iaWxlIERvY3VtZW50czpjb21+YXBwbGV+Q2xvdWREb2NzOlJuRDpQYXBlcnM6MjA3ZTFiOWMtZWQwNy00YzdlLTk3ZTQtNTM1ZjMwNWI0YzFlLnBkZgAOAFIAKAAyADAANwBlADEAYgA5AGMALQBlAGQAMAA3AC0ANABjADcAZQAtADkANwBlADQALQA1ADMANQBmADMAMAA1AGIANABjADEAZQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAblVzZXJzL2FydW5pbWEvTGlicmFyeS9Nb2JpbGUgRG9jdW1lbnRzL2NvbX5hcHBsZX5DbG91ZERvY3MvUm5EL1BhcGVycy8yMDdlMWI5Yy1lZDA3LTRjN2UtOTdlNC01MzVmMzA1YjRjMWUucGRmABMAAS8AABUAAgAO//8AAAAIAA0AGgAkAIoAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACmA==},
	bdsk-url-1 = {https://doi.org/10.1109/ICASSP49357.2023.10094635}}

@inproceedings{wu2022blackbox,
	author = {Wu, Xiaoliang},
	booktitle = {Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering},
	date-added = {2024-04-14 17:14:28 +0200},
	date-modified = {2024-04-14 17:14:28 +0200},
	pages = {1765--1769},
	title = {Blackbox adversarial attacks and explanations for automatic speech recognition},
	year = {2022},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBSQmxhY2tib3ggQWR2ZXJzYXJpYWwgQXR0YWNrcyBhbmQgRXhwbGFuYXRpb25zIGZvciBBdXRvbWF0aWMgU3BlZWNoIFJlY29nbml0aW9uLnBkZk8RAloAAAAAAloAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAONck9NCRAAB/////x9CbGFja2JveCBBZHZlcnNhcmkjRkZGRkZGRkYucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////4idPjQAAAAAAAAAAAAEAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACAGwvOlVzZXJzOmFydW5pbWE6RG93bmxvYWRzOkJsYWNrYm94IEFkdmVyc2FyaWFsIEF0dGFja3MgYW5kIEV4cGxhbmF0aW9ucyBmb3IgQXV0b21hdGljIFNwZWVjaCBSZWNvZ25pdGlvbi5wZGYADgCmAFIAQgBsAGEAYwBrAGIAbwB4ACAAQQBkAHYAZQByAHMAYQByAGkAYQBsACAAQQB0AHQAYQBjAGsAcwAgAGEAbgBkACAARQB4AHAAbABhAG4AYQB0AGkAbwBuAHMAIABmAG8AcgAgAEEAdQB0AG8AbQBhAHQAaQBjACAAUwBwAGUAZQBjAGgAIABSAGUAYwBvAGcAbgBpAHQAaQBvAG4ALgBwAGQAZgAPABoADABNAGEAYwBpAG4AdABvAHMAaAAgAEgARAASAGpVc2Vycy9hcnVuaW1hL0Rvd25sb2Fkcy9CbGFja2JveCBBZHZlcnNhcmlhbCBBdHRhY2tzIGFuZCBFeHBsYW5hdGlvbnMgZm9yIEF1dG9tYXRpYyBTcGVlY2ggUmVjb2duaXRpb24ucGRmABMAAS8AABUAAgAO//8AAAAIAA0AGgAkAHkAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAC1w==}}

@article{10143311,
	author = {Sun, Tianli and Chen, Haonan and Hu, Guosheng and He, Lianghua and Zhao, Cairong},
	date-added = {2024-04-12 14:05:14 +0200},
	date-modified = {2024-04-12 14:05:14 +0200},
	doi = {10.1109/TMM.2023.3282488},
	journal = {IEEE Transactions on Multimedia},
	keywords = {Transformers;Analytical models;Visualization;Predictive models;Data models;Computational modeling;Training;Explainability;transformer;speech recognition;attention visualization},
	pages = {1395-1406},
	title = {Explainability of Speech Recognition Transformers via Gradient-Based Attention Visualization},
	volume = {26},
	year = {2024},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBiRXhwbGFpbmFiaWxpdHlfb2ZfU3BlZWNoX1JlY29nbml0aW9uX1RyYW5zZm9ybWVyc192aWFfR3JhZGllbnQtQmFzZWRfQXR0ZW50aW9uX1Zpc3VhbGl6YXRpb24tNS5wZGZPEQKaAAAAAAKaAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADjXJPTQkQAAf////8fRXhwbGFpbmFiaWxpdHlfb2ZfI0ZGRkZGRkZGLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////+JBwbAAAAAAAAAAAAABAAIAAAogY3UAAAAAAAAAAAAAAAAACURvd25sb2FkcwAAAgB8LzpVc2VyczphcnVuaW1hOkRvd25sb2FkczpFeHBsYWluYWJpbGl0eV9vZl9TcGVlY2hfUmVjb2duaXRpb25fVHJhbnNmb3JtZXJzX3ZpYV9HcmFkaWVudC1CYXNlZF9BdHRlbnRpb25fVmlzdWFsaXphdGlvbi01LnBkZgAOAMYAYgBFAHgAcABsAGEAaQBuAGEAYgBpAGwAaQB0AHkAXwBvAGYAXwBTAHAAZQBlAGMAaABfAFIAZQBjAG8AZwBuAGkAdABpAG8AbgBfAFQAcgBhAG4AcwBmAG8AcgBtAGUAcgBzAF8AdgBpAGEAXwBHAHIAYQBkAGkAZQBuAHQALQBCAGEAcwBlAGQAXwBBAHQAdABlAG4AdABpAG8AbgBfAFYAaQBzAHUAYQBsAGkAegBhAHQAaQBvAG4ALQA1AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgB6VXNlcnMvYXJ1bmltYS9Eb3dubG9hZHMvRXhwbGFpbmFiaWxpdHlfb2ZfU3BlZWNoX1JlY29nbml0aW9uX1RyYW5zZm9ybWVyc192aWFfR3JhZGllbnQtQmFzZWRfQXR0ZW50aW9uX1Zpc3VhbGl6YXRpb24tNS5wZGYAEwABLwAAFQACAA7//wAAAAgADQAaACQAiQAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAMn},
	bdsk-url-1 = {https://doi.org/10.1109/TMM.2023.3282488}}

@article{doi:10.34133/icomputing.0074,
	abstract = {Artificial intelligence (AI) capabilities have grown rapidly with the introduction of cutting-edge deep-model architectures and learning strategies. Explainable AI (XAI) methods aim to make the capabilities of AI models beyond accuracy interpretable by providing explanations. The explanations are mainly used to increase model transparency, debug the model, and justify the model predictions to the end user. Most current XAI methods focus on providing visual and textual explanations that are prone to being present in visual media. However, audio explanations are crucial because of their intuitiveness in audio-based tasks and higher expressiveness than other modalities in specific scenarios, such as when understanding visual explanations requires expertise. In this review, we provide an overview of XAI methods for audio in 2 categories: exploiting generic XAI methods to explain audio models, and XAI methods specialised for the interpretability of audio models. Additionally, we discuss certain open problems and highlight future directions for the development of XAI techniques for audio modeling.},
	author = {Alican Akman and Bj{\"o}rn W. Schuller},
	date-added = {2024-04-12 13:51:54 +0200},
	date-modified = {2024-04-12 13:51:54 +0200},
	doi = {10.34133/icomputing.0074},
	eprint = {https://spj.science.org/doi/pdf/10.34133/icomputing.0074},
	journal = {Intelligent Computing},
	pages = {0074},
	title = {Audio Explainable Artificial Intelligence: A Review},
	url = {https://spj.science.org/doi/abs/10.34133/icomputing.0074},
	volume = {3},
	year = {2024},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxATaWNvbXB1dGluZy4wMDc0LnBkZk8RAWAAAAAAAWAAAgAADE1hY2ludG9zaCBIRAAAAAAAAAAAAAAAAAAAAONck9NCRAAB/////xNpY29tcHV0aW5nLjAwNzQucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAD/////4j7u4wAAAAAAAAAAAAEAAgAACiBjdQAAAAAAAAAAAAAAAAAJRG93bmxvYWRzAAACAC0vOlVzZXJzOmFydW5pbWE6RG93bmxvYWRzOmljb21wdXRpbmcuMDA3NC5wZGYAAA4AKAATAGkAYwBvAG0AcAB1AHQAaQBuAGcALgAwADAANwA0AC4AcABkAGYADwAaAAwATQBhAGMAaQBuAHQAbwBzAGgAIABIAEQAEgArVXNlcnMvYXJ1bmltYS9Eb3dubG9hZHMvaWNvbXB1dGluZy4wMDc0LnBkZgAAEwABLwAAFQACAA7//wAAAAgADQAaACQAOgAAAAAAAAIBAAAAAAAAAAUAAAAAAAAAAAAAAAAAAAGe},
	bdsk-url-1 = {https://spj.science.org/doi/abs/10.34133/icomputing.0074},
	bdsk-url-2 = {https://doi.org/10.34133/icomputing.0074}}

@inproceedings{10095894,
	author = {Wang, Changhong and Lostanlen, Vincent and Lagrange, Mathieu},
	booktitle = {ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	date-added = {2024-04-12 13:45:09 +0200},
	date-modified = {2024-04-12 13:45:09 +0200},
	doi = {10.1109/ICASSP49357.2023.10095894},
	keywords = {Taxonomy;Scattering;Transforms;Speech recognition;Production;Multiple signal classification;Timbre;Layer-wise relevance propagation;scattering transform;playing technique recognition;music signal analysis},
	pages = {1-5},
	title = {Explainable audio Classification of Playing Techniques with Layer-wise Relevance Propagation},
	year = {2023},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBgRXhwbGFpbmFibGVfYXVkaW9fQ2xhc3NpZmljYXRpb25fb2ZfUGxheWluZ19UZWNobmlxdWVzX3dpdGhfTGF5ZXItd2lzZV9SZWxldmFuY2VfUHJvcGFnYXRpb24ucGRmTxECkgAAAAACkgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAA41yT00JEAAH/////H0V4cGxhaW5hYmxlX2F1ZGlvXyNGRkZGRkZGRi5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/////iPut+AAAAAAAAAAAAAQACAAAKIGN1AAAAAAAAAAAAAAAAAAlEb3dubG9hZHMAAAIAei86VXNlcnM6YXJ1bmltYTpEb3dubG9hZHM6RXhwbGFpbmFibGVfYXVkaW9fQ2xhc3NpZmljYXRpb25fb2ZfUGxheWluZ19UZWNobmlxdWVzX3dpdGhfTGF5ZXItd2lzZV9SZWxldmFuY2VfUHJvcGFnYXRpb24ucGRmAA4AwgBgAEUAeABwAGwAYQBpAG4AYQBiAGwAZQBfAGEAdQBkAGkAbwBfAEMAbABhAHMAcwBpAGYAaQBjAGEAdABpAG8AbgBfAG8AZgBfAFAAbABhAHkAaQBuAGcAXwBUAGUAYwBoAG4AaQBxAHUAZQBzAF8AdwBpAHQAaABfAEwAYQB5AGUAcgAtAHcAaQBzAGUAXwBSAGUAbABlAHYAYQBuAGMAZQBfAFAAcgBvAHAAYQBnAGEAdABpAG8AbgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAeFVzZXJzL2FydW5pbWEvRG93bmxvYWRzL0V4cGxhaW5hYmxlX2F1ZGlvX0NsYXNzaWZpY2F0aW9uX29mX1BsYXlpbmdfVGVjaG5pcXVlc193aXRoX0xheWVyLXdpc2VfUmVsZXZhbmNlX1Byb3BhZ2F0aW9uLnBkZgATAAEvAAAVAAIADv//AAAACAANABoAJACHAAAAAAAAAgEAAAAAAAAABQAAAAAAAAAAAAAAAAAAAx0=},
	bdsk-url-1 = {https://doi.org/10.1109/ICASSP49357.2023.10095894}}

@inproceedings{mathew2021hatexplain,
	author = {Mathew, Binny and Saha, Punyajoy and Yimam, Seid Muhie and Biemann, Chris and Goyal, Pawan and Mukherjee, Animesh},
	booktitle = {Proceedings of the AAAI conference on artificial intelligence},
	date-added = {2024-04-10 15:06:21 +0200},
	date-modified = {2024-04-10 15:06:21 +0200},
	number = {17},
	pages = {14867--14875},
	title = {Hatexplain: A benchmark dataset for explainable hate speech detection},
	volume = {35},
	year = {2021},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXkhhdGVYcGxhaW4ucGRmTxEBSgAAAAABSgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAA41yT00JEAAH/////DkhhdGVYcGxhaW4ucGRmAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/////iJ054AAAAAAAAAAAAAQACAAAKIGN1AAAAAAAAAAAAAAAAAAlEb3dubG9hZHMAAAIAKC86VXNlcnM6YXJ1bmltYTpEb3dubG9hZHM6SGF0ZVhwbGFpbi5wZGYADgAeAA4ASABhAHQAZQBYAHAAbABhAGkAbgAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAJlVzZXJzL2FydW5pbWEvRG93bmxvYWRzL0hhdGVYcGxhaW4ucGRmABMAAS8AABUAAgAO//8AAAAIAA0AGgAkADMAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAABgQ==}}

@inproceedings{wu2024can,
	author = {Wu, Xiaoliang and Bell, Peter and Rajan, Ajitha},
	booktitle = {ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	date-added = {2024-04-10 15:04:32 +0200},
	date-modified = {2024-04-10 15:04:32 +0200},
	organization = {IEEE},
	pages = {10296--10300},
	title = {Can we trust explainable ai methods on asr? an evaluation on phoneme recognition},
	year = {2024},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxB0Li4vTGlicmFyeS9Nb2JpbGUgRG9jdW1lbnRzL2NvbX5hcHBsZX5DbG91ZERvY3MvUm5EL1BhcGVycy9XdSwgQmVsbCBldCBhbCAyOTA1MjAyMyAtIENhbiBXZSBUcnVzdCBFeHBsYWluYWJsZSBBSS5wZGZPEQJQAAAAAAJQAAIAAAxNYWNpbnRvc2ggSEQAAAAAAAAAAAAAAAAAAADjXJPTQkQAAf////8fV3UsIEJlbGwgZXQgYWwgMjkwI0ZGRkZGRkZGLnBkZgAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA/////+ICYeoAAAAAAAAAAAABAAYAAAogY3UAAAAAAAAAAAAAAAAABlBhcGVycwACAIEvOlVzZXJzOmFydW5pbWE6TGlicmFyeTpNb2JpbGUgRG9jdW1lbnRzOmNvbX5hcHBsZX5DbG91ZERvY3M6Um5EOlBhcGVyczpXdSwgQmVsbCBldCBhbCAyOTA1MjAyMyAtIENhbiBXZSBUcnVzdCBFeHBsYWluYWJsZSBBSS5wZGYAAA4AdAA5AFcAdQAsACAAQgBlAGwAbAAgAGUAdAAgAGEAbAAgADIAOQAwADUAMgAwADIAMwAgAC0AIABDAGEAbgAgAFcAZQAgAFQAcgB1AHMAdAAgAEUAeABwAGwAYQBpAG4AYQBiAGwAZQAgAEEASQAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAf1VzZXJzL2FydW5pbWEvTGlicmFyeS9Nb2JpbGUgRG9jdW1lbnRzL2NvbX5hcHBsZX5DbG91ZERvY3MvUm5EL1BhcGVycy9XdSwgQmVsbCBldCBhbCAyOTA1MjAyMyAtIENhbiBXZSBUcnVzdCBFeHBsYWluYWJsZSBBSS5wZGYAABMAAS8AABUAAgAO//8AAAAIAA0AGgAkAJsAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAAC7w==}}

@article{haunschmid2020audiolime,
	author = {Haunschmid, Verena and Manilow, Ethan and Widmer, Gerhard},
	date-added = {2024-04-10 15:02:17 +0200},
	date-modified = {2024-04-10 15:02:17 +0200},
	journal = {arXiv preprint arXiv:2008.00582},
	title = {audiolime: Listenable explanations using source separation},
	year = {2020},
	bdsk-file-1 = {YnBsaXN0MDDSAQIDBFxyZWxhdGl2ZVBhdGhZYWxpYXNEYXRhXxBLLi4vTGlicmFyeS9Nb2JpbGUgRG9jdW1lbnRzL2NvbX5hcHBsZX5DbG91ZERvY3MvUm5EL1BhcGVycy8yMDA4LjAwNTgydjMucGRmTxEBqgAAAAABqgACAAAMTWFjaW50b3NoIEhEAAAAAAAAAAAAAAAAAAAA41yT00JEAAH/////EDIwMDguMDA1ODJ2My5wZGYAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAP/////iAmHqAAAAAAAAAAAAAQAGAAAKIGN1AAAAAAAAAAAAAAAAAAZQYXBlcnMAAgBYLzpVc2VyczphcnVuaW1hOkxpYnJhcnk6TW9iaWxlIERvY3VtZW50czpjb21+YXBwbGV+Q2xvdWREb2NzOlJuRDpQYXBlcnM6MjAwOC4wMDU4MnYzLnBkZgAOACIAEAAyADAAMAA4AC4AMAAwADUAOAAyAHYAMwAuAHAAZABmAA8AGgAMAE0AYQBjAGkAbgB0AG8AcwBoACAASABEABIAVlVzZXJzL2FydW5pbWEvTGlicmFyeS9Nb2JpbGUgRG9jdW1lbnRzL2NvbX5hcHBsZX5DbG91ZERvY3MvUm5EL1BhcGVycy8yMDA4LjAwNTgydjMucGRmABMAAS8AABUAAgAO//8AAAAIAA0AGgAkAHIAAAAAAAACAQAAAAAAAAAFAAAAAAAAAAAAAAAAAAACIA==}}
@INPROCEEDINGS{10669910,
  author={Javadi, Golara and Yuksel, Kamer Ali and Kim, Yunsu and Ferreira, Thiago Castro and Al-Badrashiny, Mohamed},
  booktitle={2024 IEEE International Conference on Acoustics, Speech, and Signal Processing Workshops (ICASSPW)}, 
  title={Word-Level ASR Quality Estimation for Efficient Corpus Sampling and Post-Editing Through Analyzing Attentions of a Reference-Free Metric}, 
  year={2024},
  volume={},
  number={},
  pages={863-867},
  keywords={Training;Explainable AI;Error analysis;Source coding;Refining;Decision making;Estimation;Automatic Speech Recognition;Explain-ability;Reference-less Metric;Quality Estimation},
  doi={10.1109/ICASSPW62465.2024.10669910}}

@article{rabiner2007introduction,
  title={Introduction to digital speech processing},
  author={Rabiner, Lawrence R and Schafer, Ronald W and others},
  journal={Foundations and Trends{\textregistered} in Signal Processing},
  volume={1},
  number={1--2},
  pages={1--194},
  year={2007},
  publisher={Now Publishers, Inc.}
}
@book{symons2013digital,
  title={Digital waveform generation},
  author={Symons, Pete},
  year={2013},
  publisher={Cambridge University Press}
}
  @misc{mel_scale,
    title = {Mel scale},
    howpublished = {\url{https://en.wikipedia.org/wiki/Mel_scale}},
    note = {Accessed: 2023-10-05}
  }
@misc{stanford_nlp_lecture,
  author = {Christopher Manning},
  title = {Lecture 6: Speech Recognition and Synthesis},
  year = {2023},
  howpublished = {\url{https://nlp.stanford.edu/courses/lsa352/lsa352.lec6.6up.pdf}},
  note = {Accessed: 2023-10-05}
}
@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, A},
  journal={Advances in Neural Information Processing Systems},
  year={2017}
}
@book{bishop2006pattern,
  title={Pattern Recognition and Machine Learning},
  author={Bishop, Christopher M.},
  year={2006},
  publisher={Springer},
  address={New York},
  isbn={978-0-387-31073-2}
}
@article{dosovitskiy2020image,
  title={An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale},
  author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and Uszkoreit, Jakob and Houlsby, Neil},
  journal={arXiv preprint arXiv:2010.11929},
  year={2020}
}
@inproceedings{sun2020explaining,
  title={Explaining image classifiers using statistical fault localization},
  author={Sun, Youcheng and Chockler, Hana and Huang, Xiaowei and Kroening, Daniel},
  booktitle={European conference on computer vision},
  pages={391--406},
  year={2020},
  organization={Springer}
}
@inproceedings{ribeiro2016should,
  title={" Why should i trust you?" Explaining the predictions of any classifier},
  author={Ribeiro, Marco Tulio and Singh, Sameer and Guestrin, Carlos},
  booktitle={Proceedings of the 22nd ACM SIGKDD international conference on knowledge discovery and data mining},
  pages={1135--1144},
  year={2016}
}
@inproceedings{chockler2021explanations,
  title={Explanations for occluded images},
  author={Chockler, Hana and Kroening, Daniel and Sun, Youcheng},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={1234--1243},
  year={2021}
}

@InProceedings{pmlr-v202-mao23b,
  title = 	 {Cross-Entropy Loss Functions: Theoretical Analysis and Applications},
  author =       {Mao, Anqi and Mohri, Mehryar and Zhong, Yutao},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {23803--23828},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {23--29 Jul},
  publisher =    {PMLR},
  pdf = 	 {https://proceedings.mlr.press/v202/mao23b/mao23b.pdf},
  url = 	 {https://proceedings.mlr.press/v202/mao23b.html},
  abstract = 	 {Cross-entropy is a widely used loss function in applications. It coincides with the logistic loss applied to the outputs of a neural network, when the softmax is used. But, what guarantees can we rely on when using cross-entropy as a surrogate loss? We present a theoretical analysis of a broad family of loss functions, <em>comp-sum losses</em>, that includes cross-entropy (or logistic loss), generalized cross-entropy, the mean absolute error and other cross-entropy-like loss functions. We give the first $H$-consistency bounds for these loss functions. These are non-asymptotic guarantees that upper bound the zero-one loss estimation error in terms of the estimation error of a surrogate loss, for the specific hypothesis set $H$ used. We further show that our bounds are <em>tight</em>. These bounds depend on quantities called <em>minimizability gaps</em>. To make them more explicit, we give a specific analysis of these gaps for comp-sum losses. We also introduce a new family of loss functions, <em>smooth adversarial comp-sum losses</em>, that are derived from their comp-sum counterparts by adding in a related smooth term. We show that these loss functions are beneficial in the adversarial setting by proving that they admit $H$-consistency bounds. This leads to new adversarial robustness algorithms that consist of minimizing a regularized smooth adversarial comp-sum loss. While our main purpose is a theoretical analysis, we also present an extensive empirical analysis comparing comp-sum losses. We further report the results of a series of experiments demonstrating that our adversarial robustness algorithms outperform the current state-of-the-art, while also achieving a superior non-adversarial accuracy.}
}

@InProceedings{pmlr-v137-gordon-rodriguez20a,
  title = 	 {Uses and Abuses of the Cross-Entropy Loss: Case Studies in Modern Deep Learning},
  author =       {Gordon-Rodriguez, Elliott and Loaiza-Ganem, Gabriel and Pleiss, Geoff and Cunningham, John Patrick},
  booktitle = 	 {Proceedings on "I Can't Believe It's Not Better!" at NeurIPS Workshops},
  pages = 	 {1--10},
  year = 	 {2020},
  editor = 	 {Zosa Forde, Jessica and Ruiz, Francisco and Pradier, Melanie F. and Schein, Aaron},
  volume = 	 {137},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {12 Dec},
  publisher =    {PMLR},
  pdf = 	 {http://proceedings.mlr.press/v137/gordon-rodriguez20a/gordon-rodriguez20a.pdf},
  url = 	 {https://proceedings.mlr.press/v137/gordon-rodriguez20a.html},
  abstract = 	 {Modern deep learning is primarily an experimental science, in which empirical advances occasionally come at the expense of probabilistic rigor. Here we focus on one such example; namely the use of the categorical cross-entropy loss to model data that is not strictly categorical, but rather takes values on the simplex. This practice is standard in neural network architectures with label smoothing and actor-mimic reinforcement learning, amongst others. Drawing on the recently discovered continuous-categorical distribution, we propose probabilistically-inspired alternatives to these models, providing an approach that is more principled and theoretically appealing. Through careful experimentation, including an ablation study, we identify the potential for outperformance in these models, thereby highlighting the importance of a proper probabilistic treatment, as well as illustrating some of the failure modes thereof.}
}

